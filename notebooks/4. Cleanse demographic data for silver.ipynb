{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2f53561-6b33-45c9-8b14-f46c1d011daa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Create schema for csv file and import it as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83272671-9e59-4993-882e-425da36f9b66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, ShortType, StringType, FloatType\n",
    "\n",
    "df_schema = StructType([\n",
    "    StructField(\"STATISTIC\", StringType()),\n",
    "    StructField(\"STATISTIC Label\", StringType()),\n",
    "    StructField(\"TLIST(A1)\", ShortType()),\n",
    "    StructField(\"Census Year\", ShortType()),\n",
    "    StructField(\"C04167V04938\", StringType()),\n",
    "    StructField(\"Electoral Divisions\", StringType()),\n",
    "    StructField(\"UNIT\", StringType()),\n",
    "    StructField(\"VALUE\", FloatType())\n",
    "])\n",
    "\n",
    "df = spark.read.load('/bronze/Population_Density_and_Area_Size.csv', format='csv', header=True, schema=df_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6db752b-bc45-4e31-87cf-44f6880c8ac7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Drop some columns: \n",
    "- The 1st column is redundant.\n",
    "- The 3rd column is a duplicate of the fourth column.\n",
    "- The 5th and 7th columns are redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a224d173-a22f-41cd-91aa-37cc188ce2a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the column names\n",
    "all_columns = df.columns\n",
    "\n",
    "# Specify the indices of the columns to drop\n",
    "indices_to_drop = [0, 2, 4, 6]\n",
    "\n",
    "# Get the column names to drop based on their indices\n",
    "columns_to_drop = [all_columns[i] for i in indices_to_drop]\n",
    "\n",
    "# Drop the specified columns\n",
    "df = df.drop(*columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4511025d-1c2d-4564-8cdb-ccddf86966ea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Rename some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3f3cf5e-5816-4694-bc3f-0e435a6203e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary of columns to rename and their new names\n",
    "columns_to_rename = {\n",
    "    \"STATISTIC Label\": \"Statistic_label\",\n",
    "    \"Census Year\": \"Census_year\",\n",
    "    \"Electoral Divisions\": \"Electoral_divisions\",\n",
    "    \"VALUE\": \"Value\"\n",
    "}\n",
    "\n",
    "# Rename columns\n",
    "for old_col, new_col in columns_to_rename.items():\n",
    "    df = df.withColumnRenamed(old_col, new_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f132776f-f771-41ae-9795-7d7955597e13",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Replace null and blank values in string columns with \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43977335-ec3e-4f84-9d2a-0f31219a7b02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, lit, col\n",
    " \n",
    "string_cols = ['Statistic_label', 'Electoral_divisions']\n",
    "\n",
    "for col_name in string_cols:\n",
    "    df = df.withColumn(col_name, when(\n",
    "        (col(col_name).isNull() | (col(col_name)==\"\")), \n",
    "        lit(\"Unknown\")\n",
    "    ).otherwise(col(col_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba4f8021-cff3-4259-a5b5-762ef0c276bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Trim string columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "385c943e-3840-4668-a966-08fba5d74d17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import trim\n",
    "\n",
    "for col_name in string_cols:\n",
    "    df = df.withColumn(col_name, trim(df[col_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b19d5d0c-d51f-485f-84b4-d696807aa5f0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Write to silver layer as a delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76f12f83-e0d4-4b4e-8559-e2891ad39428",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "df.write.format(\"delta\").mode(\"append\").save(\"/delta/demographic_data_silver\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4. Cleanse demographic data for silver",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
