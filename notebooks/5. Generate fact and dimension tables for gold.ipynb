{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2adbe947-6956-4cec-a813-b9627e84a7ed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Import EV charging and vehicle licensing data as dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5c387a3-5a17-464e-a96d-3d015c35e175",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "charging_points_df = spark.read.format(\"delta\").load(\"/delta/EV_charging_points_silver\")\n",
    "vehicle_licenses_df = spark.read.format(\"delta\").load(\"/delta/vehicle_licensing_silver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "678b2c91-d62e-4f33-b555-96da3a6d857b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Use Spark SQL to aggregate number_of_chargers by Town"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a080ac26-6a10-4228-83e2-6b26640393b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "charging_points_df.createOrReplaceTempView(\"Charging_Points\")\n",
    "grouped_charging_points_df = spark.sql(\n",
    "    \"SELECT Town, SUM(Number_of_chargers) AS No_of_chargers \\\n",
    "    FROM Charging_Points \\\n",
    "    GROUP BY Town\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a285f329-765d-4bf2-8ba2-7f38d2b0a2ae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Use Spark SQL to aggregate No_of_licensed_vehicles by Town for only electric vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7deac1d-097c-4db8-9e14-a06fdc12af7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vehicle_licenses_df.createOrReplaceTempView(\"Vehicle_Licenses\")\n",
    "grouped_EV_licenses_df = spark.sql(\n",
    "    \"SELECT Town, SUM(No_of_licensed_vehicles) AS No_of_licensed_electric_vehicles \\\n",
    "    FROM Vehicle_Licenses \\\n",
    "    WHERE Type_of_fuel = 'Electric' \\\n",
    "    GROUP BY Town\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7200bcf-d66d-4a4e-a29c-189dadda988a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Perform an inner join between both aggregated dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0626b9be-e020-4aec-bcf9-52e07d97a8ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fact_df = grouped_charging_points_df.join(\n",
    "            grouped_EV_licenses_df, \n",
    "            grouped_charging_points_df[\"Town\"] == grouped_EV_licenses_df[\"Town\"], \n",
    "            \"inner\"\n",
    "          ).select(\n",
    "            grouped_charging_points_df[\"*\"], \n",
    "            grouped_EV_licenses_df[\"No_of_licensed_electric_vehicles\"]\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52d75785-00af-4534-b00c-43175ef90e15",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Import the demographic data as a dataframe and use Spark SQL to refocus it to population densities in South Dublin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "168ef9bf-4d5f-4333-82dc-c581f899338d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "demographic_df = spark.read.format(\"delta\").load(\"/delta/demographic_data_silver\")\n",
    "\n",
    "demographic_df.createOrReplaceTempView(\"Demographic_Data\")\n",
    "dim_df = spark.sql(\n",
    "    \"SELECT Statistic_label, Electoral_divisions, Value \\\n",
    "    FROM Demographic_Data \\\n",
    "    WHERE LOWER(Electoral_divisions) LIKE '%south dublin' \\\n",
    "    AND Statistic_label = 'Population density (persons per sq km)'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "645d45ae-d17d-499c-9b7e-c4bd97122115",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Extract the left-most word from **Electoral_divisions** before delimiter using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4bd941f-6a5e-448f-86d3-08f8ef876b6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col\n",
    "\n",
    "# Use regular expression to extract the first word based on multiple delimiters\n",
    "dim_df = dim_df.withColumn(\"Electoral_divisions\", regexp_extract(col(\"Electoral_divisions\"), r\"^[^\\s-_, ]+\", 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c30fcce9-ac63-4972-8958-302bec08cb19",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Pivot **Statistic_label**, taking the SUM of **Value** as its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76cbc9b9-e747-437e-9695-785dcead796d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, round\n",
    "\n",
    "# Pivot the DataFrame\n",
    "dim_df = dim_df.groupBy(\"Electoral_divisions\").pivot(\"Statistic_label\").agg(round(sum(\"Value\"), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fc667c4-8be3-4104-aa83-847da11b6b5b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Rename some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cc44ffe-5afc-456a-84d3-c04f82af5ab0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary of columns to rename and their new names\n",
    "columns_to_rename = {\n",
    "    \"Electoral_divisions\": \"Town\",\n",
    "    \"Population density (persons per sq km)\": \"Population_density\"\n",
    "}\n",
    "\n",
    "# Rename columns\n",
    "for old_col, new_col in columns_to_rename.items():\n",
    "    dim_df = dim_df.withColumnRenamed(old_col, new_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d6033ec-5895-4509-aa9d-eb81a439540f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Write to gold layer as delta tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b42fc8b-13c8-4dbb-8c9d-38e8c0363d74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "fact_df.write.format(\"delta\").mode(\"append\").save(\"/delta/fact_EV_gold\")\n",
    "dim_df.write.format(\"delta\").mode(\"append\").save(\"/delta/dim_demography_gold\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5. Generate fact and dimension tables for gold",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
